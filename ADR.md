# VibCheck - 아키텍처 결정 기록

## ADR-001: 기술 스택 선정

### 상태
승인됨

### 맥락
비개발자 바이브 코더를 위한 아이디어 검증 앱을 구축한다.
Vercel 기반으로 프론트·백엔드를 단일 프로젝트로 관리하며, 빠른 개발과 배포가 핵심이다.

### 결정
- **프레임워크**: Next.js (App Router)
- **배포**: Vercel
- **스타일링**: Tailwind CSS
- **외부 API**:
  - GitHub REST API — 유사 프로젝트 검색
  - Tavily Search API — 웹 검색/시장 분석
  - Anthropic Claude API — AI 분석 및 채팅

### 근거
- Next.js App Router: Vercel 최적 호환, API Routes로 백엔드 통합, 스트리밍 네이티브 지원
- Tailwind CSS: 빠른 UI 개발
- Vercel AI SDK: Anthropic 스트리밍 응답 처리에 최적화된 도구 제공

---

## ADR-002: UX — 리포트 + 채팅 하이브리드

### 상태
승인됨

### 맥락
비개발자가 아이디어를 검증하는 경험 형태를 결정해야 한다.

### 결정
2단계 하이브리드:
1. **리포트 단계**: 아이디어 입력 → 구조화된 검증 리포트 자동 생성
2. **채팅 단계**: 리포트 기반 Q&A, 아이디어 수정/발전

### 근거
- 리포트로 첫 판단에 필요한 정보를 구조적으로 전달 (특히 구현 가능성 판정)
- 채팅으로 궁금한 점 심화 탐색 및 아이디어 피벗 가능
- 비개발자에게 "일단 답을 주고 → 대화로 풀어가는" 경험이 가장 자연스러움

---

## ADR-003: API 호출 파이프라인

### 상태
승인됨

### 맥락
3개의 외부 API(GitHub, Tavily, Anthropic)를 효율적으로 조합해야 한다.

### 결정

```
[사용자 아이디어 입력]
        │
        ▼
[LLM 키워드 추출] ← 자연어를 효과적 검색 쿼리로 변환
        │
   ┌────┴────┐
   ▼         ▼
[GitHub]  [Tavily]  ← 병렬 호출
   │         │
   └────┬────┘
        ▼
[LLM 리포트 생성] ← 수집 데이터 + 구조화 프롬프트 → 스트리밍 출력
        │
        ▼
   [채팅 모드] ← 리포트 컨텍스트 유지
```

### 근거
- 병렬 호출로 응답 시간 최소화
- LLM 키워드 추출으로 비개발자의 모호한 표현도 정확한 검색으로 전환
- 스트리밍으로 체감 대기 시간 단축

---

## ADR-004: 리포트 구조 — 구현 가능성 최우선

### 상태
승인됨

### 맥락
리포트 섹션의 우선순위와 구조를 결정해야 한다.

### 결정
리포트 섹션 순서:
1. **구현 가능성 판정** (핵심) — 판정 등급 + 이유 + 로드맵 + 난이도 레벨링
2. **유사 프로젝트 & Build/Fork/Contribute** — 만들 것인지 기존 것을 활용할 것인지
3. **시장/트렌드 요약** (간략)

### 근거
- 비개발자 바이브 코더의 1순위 관심: "이걸 내가 만들 수 있나?"
- Build/Fork/Contribute 판단은 불필요한 노력을 줄여주는 핵심 인사이트
- 시장 분석은 부수적 — 바이브 코더는 빠르게 만들고 시장에서 검증하는 사람들
- 난이도 레벨링(바이브코딩 가능 / 조건부 / 개발자 필요 / 불가)은 비개발자에게 즉각적으로 유용한 판단 기준

---

## ADR-005: 분석 API와 채팅 API 분리

### 상태
승인됨

### 맥락
초기에는 `/api/chat` 하나로 리포트 생성과 후속 채팅을 모두 처리했으나, 검색 파이프라인(GitHub + Tavily)이 추가되면서 두 가지 역할의 요구사항이 달라졌다.

### 결정
- `POST /api/analyze` — SSE 스트림. 파이프라인 오케스트레이션 (키워드 추출 → 검색 → 랭킹 → 리포트 스트리밍). 커스텀 EventSource로 소비.
- `POST /api/chat` — Vercel AI SDK `useChat` 호환. Report를 body에 포함하여 시스템 프롬프트에 주입.

### 근거
- 분석은 멀티스텝 파이프라인(progress 이벤트 + 텍스트 스트림 + 컨텍스트 전달)이 필요하여 표준 `useChat` 프로토콜로는 부족
- 채팅은 표준 AI SDK 프로토콜이 적합 (메시지 배열 + 스트리밍 응답)
- 관심사 분리로 각각 독립적으로 테스트/수정 가능

---

## ADR-006: Phase 0 사전 심사 통합

### 상태
승인됨

### 맥락
터무니없는 아이디어("시간 여행 앱")에 대해 불필요한 검색 API 호출과 비용이 발생하는 문제.

### 결정
키워드 추출 Haiku 호출에 사전 심사를 통합. IMPOSSIBLE 판정 시 검색을 생략하고 단축 리포트를 생성.

### 근거
- 별도 API 호출 없이 기존 Haiku 호출에 분류/복잡도/데이터의존성 평가를 추가 (비용 추가 미미)
- IMPOSSIBLE 케이스에서 GitHub/Tavily 호출 완전 생략 → 건당 ~$0.04 절감
- 복잡도 × 데이터 가용성 매트릭스로 체계적 판정 가이드라인 제공

---

## ADR-007: 생태계 성숙도 신호 기반 적응형 랭킹

### 상태
승인됨

### 맥락
`stars:>5` 고정 필터는 니치 분야에서 유효한 결과를 놓치는 문제.

### 결정
2단 검색 전략 + 신호(ESTABLISHED/EMERGING/NOVEL) 분류 + 신호별 적응형 랭킹 가중치.

### 근거
- 1단(stars:>10) → 부족 시 2단(stars:>=1)으로 니치 분야 커버리지 확보
- EMERGING 신호에서는 스타 대신 최신성·커밋 빈도에 가중치를 두어 활발한 초기 프로젝트 발견
- 신호를 리포트 프롬프트에 주입하여 맥락에 맞는 판정 유도

---

## ADR-008: 모델 용도별 분리 (Opus 제외)

### 상태
승인됨

### 맥락
초기 설계에서 리포트 생성에 Opus를 사용했으나, 비용 대비 효과를 재평가함.

### 결정
- 키워드 추출 + 사전심사: Haiku 4.5 (~$0.001)
- 리포트 생성: Sonnet 4.6 (~$0.05)
- 후속 채팅: Sonnet 4.6 (~$0.02~0.04)
- Opus는 사용하지 않음

### 근거
- Sonnet이 구조화된 프롬프트 + 검색 결과 기반 분석에 충분한 품질 제공
- 1회 분석 비용 ~$0.08로 유지 (Opus 사용 시 ~$0.30+)

